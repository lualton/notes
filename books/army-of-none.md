*Notes from Army of None by Paul Sharre*


*Decision-Making Process for the Patriot Missile System*

Observe, Orient, Decide, Act
Observe: What is it? Radar detects and classifies object. A human can apply outside information and context.
Orient: Is it a valid target? Establish situational awareness. A human can apply rules of engagement.
Decide: Should we fire or not? 
	- Manual mode: A human authorizes engagement
	- Auto-fire: System will fire unless a human halts engagement
Act: System fires and the missile maneuvers to target. A human can abort the missile while in flight. 


*Human and Artificial General Intelligence do not need to exhibit similar characteristics*

Anthropomorphizing AI and assuming a machine thinks like humans limits the possibilities of how they might actually be used. There is no reason to think that a super-intelligent AI would be hostile to humans, though there's no reason it would value human life either. AI might not even value things like freedom or autonomy the way humans do.

Values can be built into AI and that's where a lot of work needs to be done. Stuarat Russell stated "A system that is optimizing a function of n variables will often set the remaining unconstrained variables to extreme values." An example of this was an AI taught to play Tetris. The goal was to never lose and the AI learned to eventually just pause the game to never lose. This is called perverse instantiation. 

*Criticisms of autonomous weapons vs criticisms of war*

We need to be able to separate arguments against autonomous weapons from arguments about war. A lot of  the morality around autonomous weapons arguments are often actually arguments about the reality of war. 

Human dignity. Just War. Morality of Killing. There are rules governing actions in war, such as never attack non-combatants (soldiers sleeping). Also such as surrender and proper handling of prisoners. There are a lot of norms governing war that have been carried and developed over time. The important part is figuring out how autonomous weapons fit into those norms. 

Getting killed by a robot that is programmed with no concept of human life seems worse than being killed by someone with a gun. Just like how getting killed in a school shooting seems so much worse than death in a car crash. 

This gets into very philosophical discussions which the book covers, but I won't write here. http://www.andrew.cmu.edu/user/ddanks/pubs.html. David Danks is a great resource for thinking about these questions. 

*Flexibility in weapons design and crisis/compressed timescales*

Greater flexibility is preferred on the battlefield. The correct decision at a given moment often depends on understanding the commander's intent. While soldiers have guidelines and plans in the field, accomplishing the commander's intent requires deviating and improvisation. Basically using common sense. 

If autonomous weapons are to be useful, there needs to be a degree of flexibility, otherwise the value is greatly diminished. From Colonel Lawrence Shattuck: "If the enemy commander has 10 possible actions and the friendly commander only has 1, the enemy clearly has the advantage."

The danger is that once autonomous weapons gain more flexibility, the strategic consequences of autonomy grows. The autonomous weapons gains an ability to do things that might be unpredictable or accelerate mistakes that are interpreted by the enemy as an escalation. And with the speed of autonomous weapons, a human decision-maker might not be able to intervene in time.

Balancing this flexibility with human control is a big issue. 

*Policy Issues around autonomous weapons*

We currently have no international definition of autonomous weapons. Nobody can fully define it. The book repeatedly mentions that the United States already uses autonomous weapons in some capacity (with human judgment and intervention). The United Nations has established a Group of Governmental Experts to discuss in 2016. Their goal has been to establish a working definition of autonomous weapons. 

The discussions around autonomous weapons bans have been spearheaded by NGO's and small states without strong militaries. This is different than many other cases such as chemical weapons and nuclear weapons. 

Banning weapons is difficult. You need clear guidelines of what exactly is banned and the weapons must exhibit a horribleness level that outweighs military value. Without a definition, this is difficult. And at the early stages of autonomous weapons, the military value is hard to predict.  

*Strategic Thinking around autonomous weapons*

There hasn't been enough thinking about the impacts of autonomous weapons on strategic stability (at least that's public). This isn't surprising as most of stability concepts around nuclear weapons emerged only after the United States was threatened. Keep on the lookout for more resources in this area. 






